
tokenize words using regex

snowball stemmer to normalize words

downloaded snowball stemmer c from https://snowballstem.org/download.html

moved relevent files to library/libstemmer/ 

changed cmakelists

also got stop words list from https://www.kaggle.com/datasets/amirhoseinsedaghati/english-stopwords?resource=download

downloading abseil for algorithms used by google's re2

using nltk regex tokenizer
https://medium.com/data-science/dynamic-word-tokenization-with-regex-tokenizer-801ae839d1cd

THINGS TO DOWNLOAD:
sudo apt install build-essential cmake pkg-config libcurl4-openssl-dev nlohmann-json3-dev

snowball stemmer (actually don't need to download, included locally)

abseil
https://abseil.io/docs/cpp/quickstart-cmake#linking-your-code-to-the-abseil-repository

re2
https://stackoverflow.com/questions/73140279/link-re2-in-cmake
